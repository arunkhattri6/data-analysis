#+title: Exploratory Data Analysis: Flu-shot Learning
#+author: Arun Khattri
#+date: Jan 20, 2024
#+property: header-args:python :session *py-session
#+property: header-args:python :tangle yes
#+options: toc:2

* Table of Contents :toc:
- [[#pre-requisites][Pre-requisites]]
  - [[#importing-packages][Importing packages]]
- [[#data][Data]]
- [[#exploration][Exploration]]
  - [[#labels][labels]]
  - [[#are-the-two-target-variables-independent][Are the two target variables independent]]
  - [[#features][Features]]
- [[#building-some-models][Building some models]]
  - [[#feature-preprocessing][Feature Preprocessing]]
  - [[#estimators][Estimators]]
  - [[#putting-together-the-full-pipeline][Putting together the full pipeline]]
  - [[#training-and-evaluation][Training and Evaluation]]
- [[#retrain-model-on-full-dataset][Retrain model on full dataset]]
- [[#generating-the-predictions-for-the-test-set][Generating the predictions for the test set]]
- [[#footnotes][Footnotes]]

* Pre-requisites
This analysis is 100% influenced by drivendata blog[fn:1]. Primary purpose was to understand quick exploratory analysis, training simple model, make some predictions and then submit those predictions to the competition.

** Importing packages
#+begin_src python :session *py-session  :exports code :tangle yes
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#+end_src

#+RESULTS:
: None

* Data
loading training data ...

#+begin_src python :session *py-session :results output :exports both :tangle yes
train = pd.read_csv("./data/training_set_features.csv", index_col="respondent_id")
labels_train = pd.read_csv("./data/training_set_labels.csv", index_col="respondent_id")
print(f"train shape:       {train.shape}")
print(f"train label shape: {labels_train.shape}")
#+end_src

#+RESULTS:
: train shape:       (26707, 35)
: train label shape: (26707, 2)

Sanity check for having same observations in labels and features data of training set...

#+begin_src python :session *py-session :results output :exports both :tangle yes
np.testing.assert_array_equal(train.index.values, labels_train.index.values)
#+end_src

#+RESULTS:

the assertion ran and nothing happen, so far so good.

Combining the features and labels for training data

#+begin_src python :session *py-session :results output :exports both :tangle yes
train_df = train.join(labels_train)
print(f"[-] train_df shape: {train_df.shape}")
#+end_src

#+RESULTS:
: [-] train_df shape: (26707, 37)


loading test data and examining the shape ...

#+begin_src python :session *py-session :results output :exports both :tangle yes
test = pd.read_csv("./data/test_set_features.csv")
print(f"test shape: {test.shape}")
#+end_src

#+RESULTS:
: test shape: (26708, 36)

* Exploration

** labels
taking a look at distribution of two target variables.

#+begin_src python :session *py-session :results output file :exports both :tangle yes
fig, ax = plt.subplots(2, 1, sharex=True)

n_obs = labels_train.shape[0]
(labels_train['h1n1_vaccine']
 .value_counts()
 .div(n_obs)
 .plot.barh(title="Proportion of H1N1 vaccine", ax=ax[0]))
ax[0].set_ylabel('h1n1_vaccine')
(labels_train['seasonal_vaccine']
 .value_counts()
 .div(n_obs)
 .plot.barh(title="Proportion of Seasonal vaccine", ax=ax[1]))
ax[1].set_ylabel('seasonal_vaccine')
fig.tight_layout()
plt.savefig("img/labels_prop.png")
print("img/labels_prop.png")
#+end_src

#+RESULTS:
[[file:img/labels_prop.png]]

It looks like half of people received the seasonal flu vaccine, however only about 20% of people got vaccinated for H1N1 flu vaccine.
In terms of class balance, seasonal flu vaccine target is fairly balanced, however H1N1 flu vaccine target has moderately imbalanced classes.

** Are the two target variables independent

#+begin_src python :session *py-session :results output :exports both :tangle yes
print(
    pd.crosstab(
        labels_train['h1n1_vaccine'],
        labels_train['seasonal_vaccine'],
        margins=True,
        normalize=True)
)
#+end_src

#+RESULTS:
: seasonal_vaccine         0         1       All
: h1n1_vaccine
: 0                 0.497810  0.289737  0.787546
: 1                 0.036582  0.175871  0.212454
: All               0.534392  0.465608  1.000000

Correlation, Phi coefficient is the same as Pearson for two binary variables

#+begin_src python :session *py-session :results output :exports both :tangle yes
labels_corr = labels_train["h1n1_vaccine"].corr(labels_train["seasonal_vaccine"],
                                  method="pearson")
print(f"{labels_corr:.2f}")
#+end_src

#+RESULTS:
: 0.38

Two variables are having phi-coefficient of 0.38, indicating a moderate positive correlation.
Most people who got an H1N1 vaccine also got the seasonal vaccine. While the minority of people who got seasonal vaccine also got H1N1 vaccine.

** Features
Let's see how the features are correlated with the target variables.

We'll start by trying to visualize if there is simple bivariate correlation. If a feature is correlated with the target, we'd expect there to be different patterns of vaccination as we vary the values of the feature.

Start by using =h1n1_concern=, the level of concern the person showed about the /H1N1 flu/, and =h1n1_vaccine= as a target variable.

get the count of observations for each combination of those two variables.

#+begin_src python :session *py-session :results output :exports both :tangle yes
counts = (train_df[['h1n1_concern', 'h1n1_vaccine']]
          .groupby(['h1n1_concern', 'h1n1_vaccine'])
          .size()
          .unstack('h1n1_vaccine'))
print(counts)
#+end_src

#+RESULTS:
: h1n1_vaccine     0     1
: h1n1_concern
: 0.0           2849   447
: 1.0           6756  1397
: 2.0           8102  2473
: 3.0           3250  1341

creating a bar chart for better visualization of patterns

#+begin_src python :session *py-session :results output file :exports both :tangle yes
fig, ax = plt.subplots(figsize=(12, 9))
ax = counts.plot.barh()
ax.invert_yaxis()
ax.legend(
    loc='best',
    title='h1n1_vaccine'
)
plt.savefig("img/bar_h1n1_concern.png")
print("img/bar_h1n1_concern.png")
# plt.show()
#+end_src

#+RESULTS:
[[file:img/bar_h1n1_concern.png]]

Still, it's hard to say =h1n1_concern= helped somebody to get vaccinated. Also two classes are imbalanced, that's why the fewer vaccination's.

Let's explore the rate of vaccination for each level of =h1n1_concern=.

#+begin_src python :session *py-session :results output :exports both :tangle yes
h1n1_concern_count = counts.sum(axis='columns')
print(f"[-] h1n1_concern counts:\n{h1n1_concern_count}")

# proportion
props = counts.div(h1n1_concern_count, axis='index')
print(f"[-] props:\n{props}")
#+end_src

#+RESULTS:
#+begin_example
[-] h1n1_concern counts:
h1n1_concern
0.0     3296
1.0     8153
2.0    10575
3.0     4591
dtype: int64
[-] props:
h1n1_vaccine         0         1
h1n1_concern
0.0           0.864381  0.135619
1.0           0.828652  0.171348
2.0           0.766147  0.233853
3.0           0.707907  0.292093
#+end_example

Since props adds up to 1.0 and we have only two variables, making a stacked bar, to make it easier to read.

#+begin_src python :session *py-session :results graphics file output :file img/prop_h1n1_concern_stacked.png :exports both :tangle yes
ax = props.plot.barh(stacked=True)
ax.invert_yaxis()
ax.legend(
    loc='center left',
    bbox_to_anchor=(1.0, 0.5),
    title='h1n1_vaccine'
)
# legend to be shown
plt.subplots_adjust(right=0.8)
#+end_src

#+RESULTS:
[[file:img/prop_h1n1_concern_stacked.png]]

Now we can say they are more likely to get vaccinated if they are having higher level of concern.

making a function so that we can plot easily and observe other variables.

#+begin_src python :session *py-session :results output  :exports both :tangle yes
def vaccination_rate_plot(col, target, data, ax=None):
    """Stacked bar chart of vaccination rate for `target` against `col`.
    Args:
        col (string): column name of feature variable
        target (string): column name of target variable
        data (pandas DataFrame): dataframe that contains
        column `col` and `target`
        ax (matplotlib,axes object, optional): matplotlib axes
        object to attach plot to
    """
    counts = (train_df[[target, col]]
                .groupby([target, col])
                .size()
                .unstack(target)
                )
    grp_counts = counts.sum(axis='columns')
    props = counts.div(grp_counts, axis='index')

    props.plot(kind='barh', stacked=True, ax=ax)
    ax.invert_yaxis()
    ax.legend().remove()
#+end_src

#+RESULTS:

Now we'll loop through several columns and plot against both =h1n1_vaccine= and =seasonal_vaccine=.

#+begin_src python :session *py-session :results graphics file output :file img/features_vs_target.png :exports both :tangle yes
concern_and_knowledge_cols = [
    'h1n1_concern',
    'h1n1_knowledge',
    ]
risk_effective_op_cols = [
    'opinion_h1n1_vacc_effective',
    'opinion_h1n1_risk',
    'opinion_h1n1_sick_from_vacc',
    'opinion_seas_vacc_effective',
    'opinion_seas_risk',
    'opinion_seas_sick_from_vacc',
]
demographic_cols = ['sex', 'age_group', 'race']

n = len(concern_and_knowledge_cols)
fig, ax = plt.subplots(
    n, 2, figsize=(9, n*2.5)
)

for idx, col in enumerate(concern_and_knowledge_cols):
    vaccination_rate_plot(col, 'h1n1_vaccine', train_df, ax=ax[idx, 0])
    vaccination_rate_plot(col, 'seasonal_vaccine', train_df, ax=ax[idx, 1])

ax[0, 0].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'h1n1_vaccine')
ax[0, 1].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'seasonal_vaccine')
fig.tight_layout()
#+end_src

#+RESULTS:
[[file:img/features_vs_target.png]]

for opinions regarding effectiveness and risks

#+begin_src python :session *py-session :results graphics file output :file img/opinion_vs_target.png :exports both :tangle yes
n = len(risk_effective_op_cols)
fig, ax = plt.subplots(
    n, 2, figsize=(9, n*2.5)
)

for idx, col in enumerate(risk_effective_op_cols):
    vaccination_rate_plot(col, 'h1n1_vaccine', train_df, ax=ax[idx, 0])
    vaccination_rate_plot(col, 'seasonal_vaccine', train_df, ax=ax[idx, 1])

ax[0, 0].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'h1n1_vaccine')
ax[0, 1].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'seasonal_vaccine')
fig.tight_layout()
#+end_src

#+RESULTS:
[[file:img/opinion_vs_target.png]]

finally plotting demographic variables against target

#+begin_src python :session *py-session :results graphics file output :file img/demographic_vs_target.png :exports both :tangle yes
n = len(demographic_cols)
fig, ax = plt.subplots(
    n, 2, figsize=(9, n * 2.5)
)

for idx, col in enumerate(demographic_cols):
    vaccination_rate_plot(col, 'h1n1_vaccine', train_df, ax=ax[idx, 0])
    vaccination_rate_plot(col, 'seasonal_vaccine', train_df, ax=ax[idx, 1])

ax[0, 0].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'h1n1_vaccine')
ax[0, 1].legend(
    loc='lower center', bbox_to_anchor=(0.5, 1.05),
    title = 'seasonal_vaccine')
fig.tight_layout()
#+end_src

#+RESULTS:
[[file:img/demographic_vs_target.png]]

It looks like knowledge and opinion questions have pretty strong signal for both target variables.

The demographic features have stronger correlation with =seasonal_vaccine=.

* Building some models
We will be using logistic regression, a simple and fast linear model for classification problems.

#+begin_src python :session *py-session :results output :exports code :tangle eda.py
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
#+end_src

#+RESULTS:

Standard logistic regression only works with numeric input for features. Since this is a benchmark, we're going to build simple models only using the numeric columns of our dataset.

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
numeric_cols = train.columns[train.dtypes != "object"].values
print(numeric_cols)
#+end_src

#+RESULTS:
: ['h1n1_concern' 'h1n1_knowledge' 'behavioral_antiviral_meds'
:  'behavioral_avoidance' 'behavioral_face_mask' 'behavioral_wash_hands'
:  'behavioral_large_gatherings' 'behavioral_outside_home'
:  'behavioral_touch_face' 'doctor_recc_h1n1' 'doctor_recc_seasonal'
:  'chronic_med_condition' 'child_under_6_months' 'health_worker'
:  'health_insurance' 'opinion_h1n1_vacc_effective' 'opinion_h1n1_risk'
:  'opinion_h1n1_sick_from_vacc' 'opinion_seas_vacc_effective'
:  'opinion_seas_risk' 'opinion_seas_sick_from_vacc' 'household_adults'
:  'household_children']

** Feature Preprocessing
There are two important data pre-processing steps before jumping to the logistic regression:
+ Scaling:
  Transform all features to be on the same scale.
+ NA Imputation:
  Logistic regression does not handle NA values. We will be using median imputation, which fills missing values with the median from the training data.

Using scikit-learn's built-in composition functionality to encapsulate everything into a pipeline.

#+begin_src python :session *py-session :results output :exports code :tangle eda.py
# chain preprocessing into a Pipeline object
# each step is a tuple of (name_you_choose, sklearn_transformer)
numeric_preprocessing_steps = Pipeline([
    ('standard_scaler', StandardScaler()),
    ('simple_imputer', SimpleImputer(strategy='median'))
])

# create the preprocessor stage of final pipeline
# each entry in the transformer list is a tuple of
# (name_choosen, sklearn_transformer, list_of_columns)
preprocessor = ColumnTransformer(
    transformers = [
        ("numeric", numeric_preprocessing_steps, numeric_cols)
    ],
    remainder = "drop"
)
#+end_src

#+RESULTS:

** Estimators
Next, we are going to define our estimators.
As we have two labels to predict, using =MultiOutputClassifier=. This is convenient shortcut for training two of the same type of model and having them run together.

#+begin_src python :session *py-session :results output :exports code :tangle eda.py
estimators = MultiOutputClassifier(
    estimator=LogisticRegression(penalty="l2", C=1)
)
#+end_src

#+RESULTS:
** Putting together the full pipeline
putting stages together into one pipeline object.

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
full_pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("estimators", estimators),
])
print(full_pipeline)
#+end_src

#+RESULTS:
#+begin_example
Pipeline(steps=[('preprocessor',
                 ColumnTransformer(transformers=[('numeric',
                                                  Pipeline(steps=[('standard_scaler',
                                                                   StandardScaler()),
                                                                  ('simple_imputer',
                                                                   SimpleImputer(strategy='median'))]),
                                                  array(['h1n1_concern', 'h1n1_knowledge', 'behavioral_antiviral_meds',
       'behavioral_avoidance', 'behavioral_face_mask',
       'behavioral_wash_hands', 'behavioral_large_gatherings',
       '...
       'chronic_med_condition', 'child_under_6_months', 'health_worker',
       'health_insurance', 'opinion_h1n1_vacc_effective',
       'opinion_h1n1_risk', 'opinion_h1n1_sick_from_vacc',
       'opinion_seas_vacc_effective', 'opinion_seas_risk',
       'opinion_seas_sick_from_vacc', 'household_adults',
       'household_children'], dtype=object))])),
                ('estimators',
                 MultiOutputClassifier(estimator=LogisticRegression(C=1)))])
#+end_example

** Training and Evaluation
Splitting data into training and evaluation set.
As our label classes were moderately imbalanced, using =stratify= argument to enforce even splits.

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
train_splits = train_test_split(
    train,
    labels_train,
    test_size=0.33,
    shuffle=True,
    stratify=labels_train,
    random_state=123
)

X_train, X_eval, y_train, y_eval  = train_splits
print(f"[-] X_train shape: {X_train.shape}")
print(f"[-] X_eval shape: {X_eval.shape}")
print(f"[-] y_train shape: {y_train.shape}")
print(f"[-] y_eval shape: {y_eval.shape}")
#+end_src

#+RESULTS:
: [-] X_train shape: (17893, 35)
: [-] X_eval shape: (8814, 35)
: [-] y_train shape: (17893, 2)
: [-] y_eval shape: (8814, 2)

let's train the model

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
st = time.time()
full_pipeline.fit(X_train, y_train)

# predict on evaluation set
preds = full_pipeline.predict_proba(X_eval)
elapsed_time = time.time() - st

print(f"[-] time taken: {elapsed_time:.4f} sec")
print(f"test_probs[0] shape: {preds[0].shape}")
print(f"test_probs[1] shape: {preds[1].shape}")
#+end_src

#+RESULTS:
: [-] time taken: 0.2312 sec
: test_probs[0] shape: (8814, 2)
: test_probs[1] shape: (8814, 2)

We need probabilities for class 1 . let's grab them...

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
y_preds = pd.DataFrame(
    {
        "h1n1_vaccine": preds[0][:, 1],
        "seasonal_vaccine": preds[1][:, 1],
    },
    index = y_eval.index
)
print(f"[-] y_preds shape: {y_preds.shape}")
print(f"[-] y_preds head:\n{y_preds.head()}")
#+end_src

#+RESULTS:
: [-] y_preds shape: (8814, 2)
: [-] y_preds head:
:                h1n1_vaccine  seasonal_vaccine
: respondent_id
: 8756               0.054788          0.901040
: 14356              0.048959          0.359612
: 7355               0.581950          0.835434
: 15794              0.500649          0.830753
: 19111              0.279736          0.781635

This driven data competition uses =ROC-AUC= as the metric. Plotting ROC curve...

#+begin_src python :session *py-session :results graphics file output :file img/roc_curve.png :exports both :tangle yes
with plt.style.context('seaborn-v0_8-colorblind'):
    def plot_roc(y_true, y_score, label_name, ax):
        """Plot ROC curve."""
        fpr, tpr, thresholds = roc_curve(y_true, y_score)
        ax.plot(fpr, tpr)
        ax.plot([0, 1], [0, 1], color="grey", linestyle="--")
        ax.set_ylabel("TPR")
        ax.set_xlabel("FPR")
        ax.set_title(
            f"{label_name}: AUC = {roc_auc_score(y_true, y_score):.4f}"
        )

    fig, ax = plt.subplots(1, 2, figsize=(9, 4.5))
    plot_roc(
        y_eval["h1n1_vaccine"],
        y_preds["h1n1_vaccine"],
        "h1n1_vaccine",
        ax=ax[0]
    )
    plot_roc(
        y_eval["seasonal_vaccine"],
        y_preds["seasonal_vaccine"],
        "seasonal_vaccine",
        ax=ax[1]
    )
    fig.tight_layout()
#+end_src

#+RESULTS:
[[file:img/roc_curve.png]]

An AUC score of 0.5 is no better than random, and an AUC score of 1.0 is a perfect model.
Both models seems performing similarly. Scores of around 0.83 are not great, however they're not bad either.

The competition metric is the average between these two AUC values. Scikit-learn's =roc_auc_score= does support multilabel...

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
auc_score = roc_auc_score(y_eval, y_preds)
print(f"AUC score: {auc_score:.4f}")
#+end_src

#+RESULTS:
: AUC score: 0.8288

* Retrain model on full dataset
Now that we have an idea of our model performance, let's retrain our model on full dataset before generating predictions on the test set.
#+begin_src python :session *py-session :results output :exports both :tangle eda.py
full_pipeline.fit(train, labels_train)
#+end_src

#+RESULTS:

* Generating the predictions for the test set
#+begin_src python :session *py-session :results output :exports both :tangle eda.py
test_probas = full_pipeline.predict_proba(test)
print(test_probas)
#+end_src

#+RESULTS:
#+begin_example
[array([[0.87280333, 0.12719667],
       [0.94475602, 0.05524398],
       [0.62906951, 0.37093049],
       ...,
       [0.80411015, 0.19588985],
       [0.9492446 , 0.0507554 ],
       [0.38421362, 0.61578638]]), array([[0.57359831, 0.42640169],
       [0.92876678, 0.07123322],
       [0.3626162 , 0.6373838 ],
       ...,
       [0.59872448, 0.40127552],
       [0.68003071, 0.31996929],
       [0.35787941, 0.64212059]])]
#+end_example

let's read the Submission format
#+begin_src python :session *py-session :results output :exports both :tangle eda.py
submission_df = pd.read_csv("./data/submission_format.csv", index_col="respondent_id")
print(submission_df.head())
#+end_src

#+RESULTS:
:                h1n1_vaccine  seasonal_vaccine
: respondent_id
: 26707                   0.5               0.7
: 26708                   0.5               0.7
: 26709                   0.5               0.7
: 26710                   0.5               0.7
: 26711                   0.5               0.7

Sanity check for similar rows order by comparing the indices...

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
np.testing.assert_array_equal(test.index.values, submission_df.index.values)
#+end_src

#+RESULTS:
So far so good. replace the data with our predictions in submission_df..

#+begin_src python :session *py-session :results output :exports both :tangle eda.py
my_submission = pd.DataFrame(
    {
        "h1n1_vaccine": test_probas[0][:, 1],
        "seasonal_vaccine": test_probas[1][:, 1],
    },
    index = submission_df.index
)
print(my_submission.head())
#+end_src

#+RESULTS:
:                h1n1_vaccine  seasonal_vaccine
: respondent_id
: 26707              0.127197          0.426402
: 26708              0.055244          0.071233
: 26709              0.370930          0.637384
: 26710              0.464351          0.803446
: 26711              0.286673          0.634903

* Footnotes

[fn:1] [[https://drivendata.co/blog/predict-flu-vaccine-data-benchmark/][Flu shot learning: Predict H1N1 and seasonal flu vaccines - benchmark]]
